{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé® ai-gen - LoRA Training & Ultra-Realistic Generation\n",
    "\n",
    "**No content restrictions. Maximum creative freedom.**\n",
    "\n",
    "This notebook sets up the complete ai-gen system on Google Colab with:\n",
    "- LoRA training (Flux models)\n",
    "- Ultra-realistic image generation\n",
    "- Dataset preprocessing & captioning\n",
    "- Web GUI with ngrok tunnel\n",
    "- All API keys pre-configured\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Instructions\n",
    "\n",
    "1. **Runtime**: Set runtime to GPU (Runtime ‚Üí Change runtime type ‚Üí T4 GPU)\n",
    "2. **Run cells in order**: Click the play button on each cell\n",
    "3. **Access GUI**: After setup, you'll get an ngrok URL to access the web interface\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## üîß Step 1: Environment Setup\n",
    "\n",
    "This cell installs all dependencies and sets up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "print(\"\\nüöÄ Starting ai-gen setup...\\n\")\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/content/ai-gen'):\n",
    "    print(\"üì• Cloning ai-gen repository...\")\n",
    "    !git clone https://github.com/SamuelD27/ai-gen.git /content/ai-gen\n",
    "else:\n",
    "    print(\"üìÅ Repository already exists, pulling latest changes...\")\n",
    "    !cd /content/ai-gen && git pull\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir('/content/ai-gen')\n",
    "\n",
    "print(\"\\n‚úÖ Repository ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deps-header"
   },
   "source": [
    "## üì¶ Step 2: Install Dependencies\n",
    "\n",
    "Installing Python packages and system dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing Python dependencies...\\n\")\n",
    "\n",
    "# Install main requirements\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Install GUI backend requirements\n",
    "!pip install -q -r charforge-gui/backend/requirements.txt\n",
    "\n",
    "# Install additional Colab-specific packages\n",
    "!pip install -q pyngrok\n",
    "\n",
    "print(\"\\n‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "env-header"
   },
   "source": [
    "## üîë Step 3: Configure API Keys\n",
    "\n",
    "Setting up pre-configured API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-env"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"üîë Configuring API keys...\\n\")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['HF_TOKEN'] = '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'\n",
    "os.environ['HF_HOME'] = '/content/.cache/huggingface'\n",
    "os.environ['CIVITAI_API_KEY'] = '68b35c5249f706b2fdf33a96314628ff'\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCkIlt1nCc5HDfKjrGvUHknmBj5PqdhTU8'\n",
    "os.environ['FAL_KEY'] = '93813d30-be3e-4bad-a0b2-dfe3a16fbb9d:8edebabc3800e0d0a6b46909f18045c8'\n",
    "\n",
    "# Create root .env file\n",
    "env_content = \"\"\"# ai-gen Environment Variables\n",
    "HF_TOKEN=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\n",
    "HF_HOME=/content/.cache/huggingface\n",
    "CIVITAI_API_KEY=68b35c5249f706b2fdf33a96314628ff\n",
    "GOOGLE_API_KEY=AIzaSyCkIlt1nCc5HDfKjrGvUHknmBj5PqdhTU8\n",
    "FAL_KEY=93813d30-be3e-4bad-a0b2-dfe3a16fbb9d:8edebabc3800e0d0a6b46909f18045c8\n",
    "APP_PATH=/content/ai-gen\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/ai-gen/.env', 'w') as f:\n",
    "    f.write(env_content)\n",
    "\n",
    "# Create backend .env file\n",
    "backend_env_content = \"\"\"# Backend Environment Variables\n",
    "SECRET_KEY=colab-secret-key-change-in-production\n",
    "DATABASE_URL=sqlite:///./database.db\n",
    "HF_TOKEN=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\n",
    "HF_HOME=/content/.cache/huggingface\n",
    "CIVITAI_API_KEY=68b35c5249f706b2fdf33a96314628ff\n",
    "GOOGLE_API_KEY=AIzaSyCkIlt1nCc5HDfKjrGvUHknmBj5PqdhTU8\n",
    "FAL_KEY=93813d30-be3e-4bad-a0b2-dfe3a16fbb9d:8edebabc3800e0d0a6b46909f18045c8\n",
    "APP_PATH=/content/ai-gen\n",
    "\"\"\"\n",
    "\n",
    "with open('/content/ai-gen/charforge-gui/backend/.env', 'w') as f:\n",
    "    f.write(backend_env_content)\n",
    "\n",
    "print(\"‚úÖ API keys configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models-header"
   },
   "source": [
    "## ü§ñ Step 4: Download Models\n",
    "\n",
    "Downloading required models (Flux, SDXL, etc.) - This may take 10-15 minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-models"
   },
   "outputs": [],
   "source": [
    "print(\"ü§ñ Downloading models...\\n\")\n",
    "print(\"‚è≥ This may take 10-15 minutes on first run...\\n\")\n",
    "\n",
    "!cd /content/ai-gen && python install.py\n",
    "\n",
    "print(\"\\n‚úÖ Models downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngrok-header"
   },
   "source": [
    "## üåê Step 5: Setup ngrok Tunnel\n",
    "\n",
    "Creating public URL to access the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-ngrok"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok, conf\n",
    "import time\n",
    "\n",
    "print(\"üåê Setting up ngrok tunnel...\\n\")\n",
    "\n",
    "# Configure ngrok with authtoken\n",
    "ngrok.set_auth_token(\"33u4PSfJRAAdkBVl0lmMTo7LebK_815Q5PcJK6h68hM5PUAyM\")\n",
    "\n",
    "print(\"‚úÖ ngrok configured!\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: ngrok tunnel will be started in the next cell when GUI launches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "launch-header"
   },
   "source": [
    "## üöÄ Step 6: Launch GUI\n",
    "\n",
    "Starting the web interface with public access.\n",
    "\n",
    "**IMPORTANT**: After running this cell, you'll get a public URL to access your GUI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch-gui"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "from pyngrok import ngrok\n",
    "import requests\n",
    "\n",
    "print(\"üöÄ Starting ai-gen GUI...\\n\")\n",
    "\n",
    "os.chdir('/content/ai-gen/charforge-gui')\n",
    "\n",
    "# Function to run backend\n",
    "def run_backend():\n",
    "    os.chdir('/content/ai-gen/charforge-gui/backend')\n",
    "    subprocess.run([\n",
    "        'uvicorn', 'app.main:app',\n",
    "        '--host', '0.0.0.0',\n",
    "        '--port', '8000'\n",
    "    ])\n",
    "\n",
    "# Function to run frontend\n",
    "def run_frontend():\n",
    "    os.chdir('/content/ai-gen/charforge-gui/frontend')\n",
    "    # Install node modules if needed\n",
    "    if not os.path.exists('node_modules'):\n",
    "        print(\"üì¶ Installing frontend dependencies...\")\n",
    "        subprocess.run(['npm', 'install'], check=True)\n",
    "    subprocess.run(['npm', 'run', 'dev', '--', '--host', '0.0.0.0', '--port', '5173'])\n",
    "\n",
    "# Start backend in background thread\n",
    "print(\"üîß Starting backend...\")\n",
    "backend_thread = threading.Thread(target=run_backend, daemon=True)\n",
    "backend_thread.start()\n",
    "\n",
    "# Wait for backend to start\n",
    "time.sleep(5)\n",
    "\n",
    "# Start frontend in background thread\n",
    "print(\"üé® Starting frontend...\")\n",
    "frontend_thread = threading.Thread(target=run_frontend, daemon=True)\n",
    "frontend_thread.start()\n",
    "\n",
    "# Wait for frontend to start\n",
    "print(\"‚è≥ Waiting for services to initialize...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Create ngrok tunnel to frontend\n",
    "print(\"\\nüåê Creating public tunnel...\")\n",
    "public_url = ngrok.connect(5173, bind_tls=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ai-gen is Running!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüì± Access your GUI here:\\n\")\n",
    "print(f\"   üåê {public_url}\\n\")\n",
    "print(\"üí° Click the link above to access your ai-gen interface\")\n",
    "print(\"üí° On first visit, click 'Visit Site' on the ngrok warning page\")\n",
    "print(\"\\nüîß Backend API: http://localhost:8000/docs\")\n",
    "print(\"\\n‚ö†Ô∏è  Keep this cell running! Stopping it will shut down the GUI.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Keep running\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüõë Shutting down...\")\n",
    "    ngrok.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-header"
   },
   "source": [
    "---\n",
    "\n",
    "## üìñ Usage Guide\n",
    "\n",
    "### Training a LoRA\n",
    "1. Click on **Media** tab\n",
    "2. Upload 15-30 images of your subject\n",
    "3. Go to **Datasets** and create a new dataset\n",
    "4. Go to **Training** and start training\n",
    "\n",
    "### Generating Images\n",
    "1. Go to **Inference** tab\n",
    "2. Select your trained LoRA\n",
    "3. Enter a prompt\n",
    "4. Click Generate\n",
    "\n",
    "### CLI Usage\n",
    "\n",
    "You can also use the CLI directly in a new cell:\n",
    "\n",
    "```python\n",
    "# Train a LoRA\n",
    "!cd /content/ai-gen && python train_character.py \\\n",
    "    --name \"my_character\" \\\n",
    "    --trigger_word \"person\" \\\n",
    "    --images_path \"./datasets/my_character\" \\\n",
    "    --steps 1000\n",
    "\n",
    "# Generate images\n",
    "!cd /content/ai-gen && python test_character.py \\\n",
    "    --lora \"my_character\" \\\n",
    "    --prompt \"person wearing a suit\" \\\n",
    "    --num_images 4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important Notes\n",
    "\n",
    "- **No content restrictions** - Safety filters are disabled by default\n",
    "- **Session persistence** - Files are saved to `/content/ai-gen/output/`\n",
    "- **Download outputs** - Right-click files in the file browser to download\n",
    "- **GPU usage** - Training requires GPU. Make sure GPU is enabled in runtime settings\n",
    "- **Colab timeout** - Free tier disconnects after ~12 hours. Pro has longer sessions\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "**GUI not loading?**\n",
    "- Make sure the launch cell is still running\n",
    "- Try refreshing the ngrok URL\n",
    "- Check if services are running: `!ps aux | grep -E \"uvicorn|vite\"`\n",
    "\n",
    "**Out of memory?**\n",
    "- Reduce batch size in training config\n",
    "- Use smaller image resolutions\n",
    "- Clear output: `!rm -rf /content/ai-gen/output/*`\n",
    "\n",
    "**Models not downloading?**\n",
    "- Check HuggingFace token is valid\n",
    "- Manually run: `!cd /content/ai-gen && python install.py`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
